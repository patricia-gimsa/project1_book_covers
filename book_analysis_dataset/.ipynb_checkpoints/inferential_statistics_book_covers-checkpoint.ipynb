{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3702c30-7e48-4c5c-8385-7eb376258304",
   "metadata": {},
   "source": [
    "## Confidence Interval for Goodreads Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac6aa42b-97e3-4555-9556-d4cacfe5fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Goodreads Rating (bestsellers): 4.01\n",
      "95% Confidence Interval for Bestseller Ratings: (np.float64(3.94231367833146), np.float64(4.08293632166854))\n",
      "Is 4.0 within the confidence interval? True\n"
     ]
    }
   ],
   "source": [
    "# Confidence Interval for Goodreads Ratings\n",
    "# Objective: Estimate the true average Goodreads rating for bestseller books, using our sample of 80 titles.\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Load the dataset of 80 bestsellers\n",
    "df = pd.read_csv(\"data/book_covers_goodreads_after_eda.csv\")\n",
    "\n",
    "# Calculate the mean and standard error of the Goodreads ratings \n",
    "mean_rating = np.mean(df['rating'])             \n",
    "sem_rating = stats.sem(df['rating'])            \n",
    "\n",
    "# Construct the 95% confidence interval for the average rating\n",
    "confidence_interval = stats.t.interval(\n",
    "    confidence=0.95,               # 95% confidence level\n",
    "    df=len(df['rating']) - 1,      # Degrees of freedom\n",
    "    loc=mean_rating,               # Sample mean\n",
    "    scale=sem_rating               # Standard error\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Goodreads Rating (bestsellers):\", round(mean_rating, 2))\n",
    "print(\"95% Confidence Interval for Bestseller Ratings:\", confidence_interval)\n",
    "\n",
    "# Check if a rating of 4.0 is within the interval\n",
    "benchmark = 4.0\n",
    "is_in_interval = confidence_interval[0] <= benchmark <= confidence_interval[1]\n",
    "print(f\"Is {benchmark} within the confidence interval?\", is_in_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a11a8-6f37-4277-a0ad-8a8cd3530ac4",
   "metadata": {},
   "source": [
    "Confidence Interval Interpretation\n",
    "The 95% confidence interval for the average Goodreads rating of our 80 curated bestsellers is approximately [3.94, 4.08]. Since the benchmark value of 4.0 falls within this range, we can be reasonably confident that the true average rating of similar bestsellers is close to 4.0.\n",
    "\n",
    "This means that even though we only analyzed 80 books, we can generalize the result: if we repeated this process with other samples of bestsellers, in 95% of cases the average rating would fall within this interval.\n",
    "\n",
    "Conclusion: Bestselling books tend to receive consistently solid ratings around 4.0, making it a reliable benchmark for perceived quality in this type of title.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291df0d-cc5a-4443-a333-66f6d2e87341",
   "metadata": {},
   "source": [
    "## Confidence Intervals by Main Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce76954-80b4-43d0-b13d-ee0d3b417c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Romance — Mean Rating: 4.03\n",
      "95% Confidence Interval: (np.float64(3.8778134652992824), np.float64(4.1885023241744))\n",
      "\n",
      "Fantasy — Mean Rating: 4.05\n",
      "95% Confidence Interval: (np.float64(3.816550291928412), np.float64(4.275214413953941))\n",
      "\n",
      "Contemporary — Mean Rating: 3.85\n",
      "95% Confidence Interval: (np.float64(3.7354894178840508), np.float64(3.965760582115949))\n",
      "\n",
      "Nonfiction — Mean Rating: 4.12\n",
      "95% Confidence Interval: (np.float64(4.0152468049515555), np.float64(4.227419861715111))\n"
     ]
    }
   ],
   "source": [
    "# Confidence Intervals by Main Genre\n",
    "# Objective: Compare average Goodreads ratings for the top 4 most common genres\n",
    "# We'll calculate 95% confidence intervals for each genre separately\n",
    "\n",
    "# List of genres to analyze\n",
    "top_genres = ['Romance', 'Fantasy', 'Contemporary', 'Nonfiction']\n",
    "\n",
    "# Loop through each genre and compute confidence interval\n",
    "for genre in top_genres:\n",
    "    \n",
    "    # Filter dataset to include only books of the current genre\n",
    "    genre_df = df[df['main_genre'] == genre]\n",
    "    \n",
    "    # Calculate mean and standard error of the rating for this genre\n",
    "    mean_rating = np.mean(genre_df['rating'])\n",
    "    sem_rating = stats.sem(genre_df['rating'])  # Standard error of the mean\n",
    "    \n",
    "    # Compute 95% confidence interval using t-distribution\n",
    "    ci = stats.t.interval(\n",
    "        confidence=0.95,                   # Confidence level\n",
    "        df=len(genre_df['rating']) - 1,    # Degrees of freedom (n - 1)\n",
    "        loc=mean_rating,                   # Sample mean\n",
    "        scale=sem_rating                   # Standard error\n",
    "    )\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"\\n{genre} — Mean Rating: {round(mean_rating, 2)}\")\n",
    "    print(f\"95% Confidence Interval: {ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6043626-c06e-46c4-8abd-6b78d15557ae",
   "metadata": {},
   "source": [
    "We computed 95% confidence intervals for the average Goodreads rating of the top 4 genres in our dataset: Romance, Fantasy, Contemporary, and Nonfiction.\n",
    "\n",
    "Fantasy and Nonfiction show slightly higher mean ratings (around 4.05 and 4.12) than Romance (~4.03) and Contemporary (~3.85).\n",
    "\n",
    "However, the confidence intervals overlap between genres like Romance and Fantasy, meaning the difference in rating is not statistically conclusive.\n",
    "\n",
    "The only interval clearly lower is Contemporary, suggesting it may be rated slightly worse — but more data would be needed to confirm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd48e4-d089-4b61-b7cf-d52d4f433f66",
   "metadata": {},
   "source": [
    "## Hypothesis 1: Books with a face-out display (Promoted = 1) tend to be more recently published than those shelved spine-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4084f370-f55e-48f7-879d-41395bb7a3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median publication year (Promoted books): 2023\n",
      "Median publication year (Non-promoted books): 2023\n",
      "U-statistic: 768.0\n",
      "P-value: 0.8175\n",
      "We fail to reject the null hypothesis: no significant difference in median publication year.\n"
     ]
    }
   ],
   "source": [
    "# H0 (Null Hypothesis): There is no difference in publication year between promoted and non-promoted books\n",
    "# H1 (Alternative Hypothesis): Promoted books tend to be more recently published\n",
    "\n",
    "# Convert publication date to numeric year\n",
    "df[\"published_year\"] = pd.to_datetime(df[\"first_published_date\"]).dt.year\n",
    "\n",
    "# Create two groups: promoted books vs non-promoted\n",
    "promoted_years = df[df[\"promoted\"] == 1][\"published_year\"]\n",
    "non_promoted_years = df[df[\"promoted\"] == 0][\"published_year\"]\n",
    "\n",
    "# Calculate the median publication year for each group\n",
    "median_promoted = promoted_years.median()\n",
    "median_non_promoted = non_promoted_years.median()\n",
    "\n",
    "# Display the medians\n",
    "print(\"Median publication year (Promoted books):\", int(median_promoted))\n",
    "print(\"Median publication year (Non-promoted books):\", int(median_non_promoted))\n",
    "\n",
    "# Perform Mann-Whitney U test (non-parametric test for medians)\n",
    "u_stat, p_value = stats.mannwhitneyu(promoted_years, non_promoted_years, alternative='two-sided')\n",
    "\n",
    "# Print the test results\n",
    "print(\"U-statistic:\", round(u_stat, 2))\n",
    "print(\"P-value:\", round(p_value, 4))\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05  # 95% confidence level\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis: promoted books tend to be more recent.\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis: no significant difference in median publication year.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5774fb-0cc5-49c2-9f42-ced4b076712a",
   "metadata": {},
   "source": [
    "Although we expected that face-out displayed books might be more recent, the test showed no significant difference in median publication year between promoted and non-promoted books, both have a median year of 2023.\n",
    "The p-value was 0.8175, much higher than the 0.05 threshold, so we fail to reject the null hypothesis. A p-value tells us how likely it is that the difference we see could be due to chance. Since our p-value is very high, we can’t confidently say that promoted books are more recent,they seem equally recent overall.\n",
    "\n",
    "Why did we use the Mann-Whitney U test?\n",
    "We used this test instead of a standard t-test because publication year is not normally distributed, and the median is a more robust metric in this case than the mean (some books are much older than others). Mann-Whitney is ideal for comparing medians between two groups when data may be skewed or contain outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d495a6-0add-4c14-81d1-22170c99f7ee",
   "metadata": {},
   "source": [
    "## Hipothesis 2: Do books with award / recognition tend to have shorter titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28aad87c-8d93-47b8-8216-622dbb705575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median title word count (Award books): 3.0\n",
      "Median title word count (No award): 2.5\n",
      "U-statistic: 723.5\n",
      "P-value: 0.396\n",
      "We fail to reject the null hypothesis: no significant difference in title length.\n"
     ]
    }
   ],
   "source": [
    "# H0 (Null Hypothesis): There is no difference in title length between books with and without award / recognition\n",
    "# H1 (Alternative Hypothesis): Books with award / recognition have shorter titles (fewer words)\n",
    "\n",
    "# Short and catchy titles may be preferred for books already boosted by an award or bestseller badge, the title doesn't need to work as hard to attract readers\n",
    "\n",
    "# Create two groups based on award recognition\n",
    "award_titles = df[df[\"award_recognition\"] == 1][\"title_word_count\"]\n",
    "no_award_titles = df[df[\"award_recognition\"] == 0][\"title_word_count\"]\n",
    "\n",
    "# Calculate medians\n",
    "median_award = award_titles.median()\n",
    "median_no_award = no_award_titles.median()\n",
    "\n",
    "# Display medians\n",
    "print(\"Median title word count (Award books):\", median_award)\n",
    "print(\"Median title word count (No award):\", median_no_award)\n",
    "\n",
    "# Mann-Whitney U test to compare medians\n",
    "u_stat, p_value = stats.mannwhitneyu(award_titles, no_award_titles, alternative='less')\n",
    "\n",
    "# Show results\n",
    "print(\"U-statistic:\", round(u_stat, 2))\n",
    "print(\"P-value:\", round(p_value, 4))\n",
    "\n",
    "# Interpret result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis: books with award recognition tend to have shorter titles.\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis: no significant difference in title length.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b669973-9f45-46ff-be75-05d3b160b549",
   "metadata": {},
   "source": [
    "We tested whether books with award / recognition tend to have shorter titles. While my hypothesis made intuitive sense from a design and marketing perspective, the data did not support it. The median title length for award-recognized books (3.0 words) was actually slightly higher than those without recognition (2.5 words), and the p-value from the Mann-Whitney U test (0.396) shows no statistically significant difference.\n",
    "We fail to reject the null hypothesis: books with or without awards have similar title lengths.\n",
    "\n",
    "We used the Mann-Whitney U test again because we were comparing medians from two independent groups, and the title word count is a non-normally distributed variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd66d4-0b4a-4640-ac91-bf9c526ca447",
   "metadata": {},
   "source": [
    "## Hypothesis 3: Does visual style depend on book genre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09455f1-0122-44b9-a39c-fb43886b7001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table:\n",
      "visual_style     illustration  photo  symbolic  typographic\n",
      "main_genre                                                 \n",
      "Classics                    2      1         0            0\n",
      "Contemporary                9      3         4            0\n",
      "Fantasy                    16      0         1            0\n",
      "Nonfiction                  4      1         2            8\n",
      "Other                       1      0         0            0\n",
      "Romance                    16      1         2            0\n",
      "Science Fiction             1      0         1            1\n",
      "Thriller                    5      0         1            0\n",
      "\n",
      "Chi-squared statistic: 50.71\n",
      "Degrees of freedom: 21\n",
      "P-value: 0.0003\n",
      "We reject the null hypothesis: visual style depends on the book's genre.\n"
     ]
    }
   ],
   "source": [
    "# H0 (Null Hypothesis): Visual style is independent of main genre\n",
    "# H1 (Alternative Hypothesis): Visual style and genre are associated, certain genres use certain styles more often\n",
    "\n",
    "# Create a contingency table: rows = genres, columns = visual styles\n",
    "contingency_table = pd.crosstab(df['main_genre'], df['visual_style'])\n",
    "\n",
    "# Display the table to check\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Perform Chi-squared test of independence\n",
    "chi2_stat, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Show results\n",
    "print(\"\\nChi-squared statistic:\", round(chi2_stat, 2))\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"P-value:\", round(p_value, 4))\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis: visual style depends on the book's genre.\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis: no significant association between visual style and genre.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af58ec-b6a8-470d-b6c2-605d841258e9",
   "metadata": {},
   "source": [
    "We used a Chi-squared test of independence because both variables — main_genre and visual_style — are categorical. This test checks whether the distribution of visual styles differs depending on the genre.\n",
    "\n",
    "With a p-value of 0.0003 (below our 0.05 threshold), we reject the null hypothesis.\n",
    "This means that visual style is not random across genres — it depends on the book’s genre.\n",
    "\n",
    "For example, Fantasy and Romance heavily favor illustrated covers, while Nonfiction is more likely to use typographic or photographic styles. This confirms patterns already seen in our EDA, now supported by statistical evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6e32f-608d-422e-bac2-e1c0fa99ce19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
