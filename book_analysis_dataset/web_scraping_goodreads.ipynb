{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483c0d61-50a4-4a15-abec-bbf6298a8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries directly in Jupyter Notebook\n",
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34f7125-8401-49dd-b18c-201f255ee3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd      # for data handling\n",
    "import requests       # to make HTTP requests\n",
    "from bs4 import BeautifulSoup   # to parse HTML content\n",
    "import time     # to delay requests\n",
    "from urllib.parse import quote_plus # to format URLs correctly\n",
    "import re  # For regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa84e31-9b20-4931-abee-442213c5dd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Price</th>\n",
       "      <th>Promoted</th>\n",
       "      <th>Dominant_color</th>\n",
       "      <th>Cover_type</th>\n",
       "      <th>Visual_style</th>\n",
       "      <th>Title_word_count</th>\n",
       "      <th>Author_name_prominent</th>\n",
       "      <th>Award_recognition</th>\n",
       "      <th>First_published_date</th>\n",
       "      <th>Page_count</th>\n",
       "      <th>Estimated_reading_time</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Subtle Art of Not Giving a Fuck</td>\n",
       "      <td>Mark Manson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.99</td>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>typographic</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Start with Why</td>\n",
       "      <td>Simon Sinek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>paperback</td>\n",
       "      <td>typographic</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Housemaid</td>\n",
       "      <td>Freida McFadden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.35</td>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>paperback</td>\n",
       "      <td>illustration</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Housemaid´s Secret</td>\n",
       "      <td>Freida McFadden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.59</td>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "      <td>paperback</td>\n",
       "      <td>illustration</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atomic Habits</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.15</td>\n",
       "      <td>1</td>\n",
       "      <td>white</td>\n",
       "      <td>paperback</td>\n",
       "      <td>typographic</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title           Author  Publisher  Genre  \\\n",
       "0  The Subtle Art of Not Giving a Fuck      Mark Manson        NaN    NaN   \n",
       "1                       Start with Why      Simon Sinek        NaN    NaN   \n",
       "2                        The Housemaid  Freida McFadden        NaN    NaN   \n",
       "3               The Housemaid´s Secret  Freida McFadden        NaN    NaN   \n",
       "4                        Atomic Habits      James Clear        NaN    NaN   \n",
       "\n",
       "   Price  Promoted Dominant_color Cover_type  Visual_style  Title_word_count  \\\n",
       "0  19.99         1            red  hardcover   typographic                 8   \n",
       "1  12.99         0          white  paperback   typographic                 3   \n",
       "2  11.35         1           blue  paperback  illustration                 2   \n",
       "3   9.59         1            red  paperback  illustration                 3   \n",
       "4  19.15         1          white  paperback   typographic                 2   \n",
       "\n",
       "   Author_name_prominent  Award_recognition  First_published_date  Page_count  \\\n",
       "0                      0                  1                   NaN         NaN   \n",
       "1                      0                  0                   NaN         NaN   \n",
       "2                      0                  1                   NaN         NaN   \n",
       "3                      0                  1                   NaN         NaN   \n",
       "4                      0                  1                   NaN         NaN   \n",
       "\n",
       "   Estimated_reading_time  Rating  \n",
       "0                     NaN     NaN  \n",
       "1                     NaN     NaN  \n",
       "2                     NaN     NaN  \n",
       "3                     NaN     NaN  \n",
       "4                     NaN     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "df_books = pd.read_csv('book_covers_visual_dataset.csv')\n",
    "\n",
    "# Display the first few rows to verify it's loaded correctly\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01ddaa5-1676-44a5-9982-0d57c91f868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text by removing extra whitespace\n",
    "def clean_string(string):\n",
    "    cleaned = re.sub(r'\\s+', ' ', string).strip()\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa42168-d71d-420a-94cc-d6fe258281ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headers that make the request look like it comes from a real browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) \"\n",
    "                  \"Gecko/20100101 Firefox/124.0\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392377c9-1965-45f4-8a34-53acf2bcc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function searches Goodreads for a book and returns the URL of the first result\n",
    "def get_goodreads_url(title):\n",
    "    # Convert the title into a URL-friendly format (replace spaces with +, etc.)\n",
    "    query = quote_plus(title)\n",
    "    \n",
    "    # Build the search URL for Goodreads\n",
    "    search_url = f\"https://www.goodreads.com/search?q={query}\"\n",
    "\n",
    "    # Send the request using our realistic browser headers\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    # If the response fails, print error and return None\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching '{title}' from Goodreads\")\n",
    "        return None\n",
    "\n",
    "    # Parse the HTML content of the search results page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Look for the first book result in the search results\n",
    "    first_result = soup.select_one('a.bookTitle')\n",
    "\n",
    "    # If a result is found, build and return the full book URL\n",
    "    if first_result:\n",
    "        return \"https://www.goodreads.com\" + first_result['href']\n",
    "    else:\n",
    "        # If no book was found, show a message and return None\n",
    "        print(f\"No results found for '{title}'\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d442bdf-e994-499c-9767-57af25b31331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function scrapes the missing fields from a Goodreads book page\n",
    "def scrape_book_details(url):\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) \"\n",
    "                  \"Gecko/20100101 Firefox/124.0\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error accessing {url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # --- Page count ---\n",
    "    try:\n",
    "        pages = soup.select_one(\".FeaturedDetails p[data-testid='pagesFormat']\").text.strip().split()[0]\n",
    "    except:\n",
    "        pages = None\n",
    "\n",
    "    # --- Rating ---\n",
    "    try:\n",
    "        rating = soup.find(class_=\"RatingStatistics__rating\").text.strip()\n",
    "    except:\n",
    "        rating = None\n",
    "\n",
    "    # --- Genre ---\n",
    "    try:\n",
    "        genre_links = soup.select(\"div[data-testid='genresList'] a\")\n",
    "        genre_list = [g.text.strip() for g in genre_links[:2]]\n",
    "        genre = \", \".join(genre_list)\n",
    "    except:\n",
    "        genre = None\n",
    "\n",
    "    # --- First published date ---\n",
    "    try:\n",
    "        pub_info = soup.select_one(\"p[data-testid='publicationInfo']\").text.strip()\n",
    "        pub_date = re.search(r\"First published (.+)\", pub_info)\n",
    "        pub_date = pub_date.group(1) if pub_date else None\n",
    "    except:\n",
    "        pub_date = None\n",
    "\n",
    "    # --- Publisher from embedded JSON ---\n",
    "    try:\n",
    "        script = soup.find(\"script\", string=lambda s: s and '\"publisher\"' in s)\n",
    "        json_text = script.string\n",
    "        publisher = re.search(r'\"publisher\":\"(.*?)\"', json_text).group(1)\n",
    "    except:\n",
    "        publisher = None\n",
    "\n",
    "    return {\n",
    "        \"Page_count\": pages,\n",
    "        \"Rating\": rating,\n",
    "        \"Genre\": genre,\n",
    "        \"First_published\": pub_date,\n",
    "        \"Publisher\": publisher\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2e7eca-c623-4443-9064-75883ee6f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodreads URL: https://www.goodreads.com/book/show/49682914-the-subtle-art-of-not-giving-a-fuck?from_search=true&from_srp=true&qid=yReuOXfqPy&rank=1\n",
      "Book details extracted:\n",
      "Page_count: 206\n",
      "Rating: 3.87\n",
      "Genre: Nonfiction, Self Help\n",
      "First_published: January 1, 2016\n",
      "Publisher: HarperCollins\n"
     ]
    }
   ],
   "source": [
    "# Test one book to check all 5 fields from Goodreads\n",
    "test_title = \"The Subtle Art of Not Giving a Fuck\"\n",
    "\n",
    "# Step 1: Get Goodreads URL from the title\n",
    "url = get_goodreads_url(test_title)\n",
    "print(\"Goodreads URL:\", url)\n",
    "\n",
    "# Step 2: Extract book details (all 5 fields)\n",
    "if url:\n",
    "    book_details = scrape_book_details(url)\n",
    "    print(\"Book details extracted:\")\n",
    "    for key, value in book_details.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Could not find a Goodreads page for this title.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c95025-5e31-41c3-85e4-6a22a82fa2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Goodreads for: The Subtle Art of Not Giving a Fuck\n",
      "Searching Goodreads for: Start with Why\n",
      "Searching Goodreads for: The Housemaid\n",
      "Searching Goodreads for: The Housemaid´s Secret\n",
      "Searching Goodreads for: Atomic Habits\n",
      "Searching Goodreads for: Onyx Storm\n",
      "Searching Goodreads for: The Vegetarian \n",
      "Searching Goodreads for: Elphie\n",
      "Searching Goodreads for: Nothing Like The Movies\n",
      "Searching Goodreads for: 1984\n",
      "Searching Goodreads for: The Seven Husbands of Evelyn Hugo\n",
      "Searching Goodreads for: The Striker\n",
      "Searching Goodreads for: We All Live Here\n",
      "Searching Goodreads for: Story of My Life\n",
      "Searching Goodreads for: Little Women\n",
      "Searching Goodreads for: The Secret History\n",
      "Searching Goodreads for: The Fourth Consort\n",
      "Searching Goodreads for: Caraval\n",
      "Searching Goodreads for: Normal People\n",
      "Searching Goodreads for: Orbital\n",
      "Searching Goodreads for: The Pumpkin Spice Café\n",
      "Searching Goodreads for: Wild Side\n",
      "Searching Goodreads for: Cleopatra and Frankenstein\n",
      "Searching Goodreads for: Taming 7\n",
      "Searching Goodreads for: Beneath the Stars\n",
      "Searching Goodreads for: Three Days in June\n",
      "Searching Goodreads for: We Do Not Part\n",
      "Searching Goodreads for: The Wood at Midwinter\n",
      "Searching Goodreads for: The Sirens\n",
      "Searching Goodreads for: Sandwich\n",
      "Searching Goodreads for: Butter\n",
      "Searching Goodreads for: Great Big Beautiful Life\n",
      "Searching Goodreads for: The Conditions of Will\n",
      "Searching Goodreads for: Fearless\n",
      "Searching Goodreads for: A Palace Near the Wing\n",
      "Searching Goodreads for: King of Nothing\n",
      "Searching Goodreads for: Sunrise on the Reaping\n",
      "Searching Goodreads for: Mythica\n",
      "Searching Goodreads for: This Is Why You Dream\n",
      "Searching Goodreads for: The Gruffalo\n",
      "Searching Goodreads for: Deep End\n",
      "Searching Goodreads for: Dream Count\n",
      "Searching Goodreads for: The Strawberry Patch Pancake House\n",
      "Searching Goodreads for: The No. 1 Ladies' Detective Agency\n",
      "Searching Goodreads for: Days at Morisaki Bookshop\n",
      "Searching Goodreads for: Greek Lessons\n",
      "Searching Goodreads for: The Let Them Theory\n",
      "Searching Goodreads for: Intermezzo\n",
      "Searching Goodreads for: Iron Flame\n",
      "Searching Goodreads for: Phantasma\n",
      "Searching Goodreads for: Blue Sisters\n",
      "Searching Goodreads for: The Creative Act: A Way of Being\n",
      "Searching Goodreads for: The Seven Year Slip\n",
      "Searching Goodreads for: Fourth Wing\n",
      "Searching Goodreads for: Binding 13\n",
      "Searching Goodreads for: Wind and Truth\n",
      "Searching Goodreads for: Babel\n",
      "Searching Goodreads for: Blackwater I: The Flood\n",
      "Searching Goodreads for: We Who Wrestle with God\n",
      "Searching Goodreads for: Nexus\n",
      "Searching Goodreads for: Letters from the Ginza Shihodo Stationery Shop\n",
      "Searching Goodreads for: The Restaurant of Lost Recipes\n",
      "Searching Goodreads for: Long Island\n",
      "Searching Goodreads for: Yellowface\n",
      "Searching Goodreads for: It Lasts Forever and Then It´s Over\n",
      "Searching Goodreads for: The Housemaid Is Watching\n",
      "Searching Goodreads for: Baumgartner\n",
      "Searching Goodreads for: My Life in Full\n",
      "Searching Goodreads for: Conversations on Love\n",
      "Searching Goodreads for: All About Love\n",
      "Searching Goodreads for: Everything I Know About Love\n",
      "Searching Goodreads for: Solito\n",
      "Searching Goodreads for: Not In Love\n",
      "Searching Goodreads for: Happy Place\n",
      "Searching Goodreads for: A Court of Thorns and Roses\n",
      "Searching Goodreads for: Just for the Summer\n",
      "Searching Goodreads for: Funny Story\n",
      "Searching Goodreads for: Play Along\n",
      "Searching Goodreads for: I Who Have Never Known Men\n",
      "Searching Goodreads for: The Life Impossible\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists for each field\n",
    "new_pages = []\n",
    "new_ratings = []\n",
    "new_genres = []\n",
    "new_dates = []\n",
    "new_publishers = []\n",
    "\n",
    "# Loop over each title\n",
    "for title in df_books['Title']:\n",
    "    print(f\"Searching Goodreads for: {title}\")\n",
    "    \n",
    "    url = get_goodreads_url(title)\n",
    "    if url:\n",
    "        details = scrape_book_details(url)\n",
    "        if details:\n",
    "            # Append the extracted values or None if missing\n",
    "            new_pages.append(details.get(\"Page_count\"))\n",
    "            new_ratings.append(details.get(\"Rating\"))\n",
    "            new_genres.append(details.get(\"Genre\"))\n",
    "            \n",
    "            # --- Format the date ---\n",
    "            raw_date = details.get(\"First_published\")\n",
    "            try:\n",
    "                date_obj = pd.to_datetime(raw_date, errors='coerce')\n",
    "                formatted_date = date_obj.strftime('%Y-%m-%d') if not pd.isna(date_obj) else None\n",
    "            except:\n",
    "                formatted_date = None\n",
    "            new_dates.append(formatted_date)\n",
    "\n",
    "            new_publishers.append(details.get(\"Publisher\"))\n",
    "        else:\n",
    "            new_pages.append(None)\n",
    "            new_ratings.append(None)\n",
    "            new_genres.append(None)\n",
    "            new_dates.append(None)\n",
    "            new_publishers.append(None)\n",
    "    else:\n",
    "        new_pages.append(None)\n",
    "        new_ratings.append(None)\n",
    "        new_genres.append(None)\n",
    "        new_dates.append(None)\n",
    "        new_publishers.append(None)\n",
    "    \n",
    "    # Wait to avoid overloading the server\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04dd0f5c-92c9-4e03-8f86-e41753bcd3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page_count filled: 80\n",
      "Rating filled: 80\n",
      "Genre filled: 80\n",
      "First_published filled: 79\n",
      "Publisher filled: 80\n"
     ]
    }
   ],
   "source": [
    "# Check how many entries were successfully scraped for each field\n",
    "print(\"Page_count filled:\", sum(x is not None for x in new_pages))\n",
    "print(\"Rating filled:\", sum(x is not None for x in new_ratings))\n",
    "print(\"Genre filled:\", sum(x is not None for x in new_genres))\n",
    "print(\"First_published filled:\", sum(x is not None for x in new_dates))\n",
    "print(\"Publisher filled:\", sum(x is not None for x in new_publishers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4538e78d-625c-4ef2-99cf-bc9caa820f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Page_count</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Genre</th>\n",
       "      <th>First_published</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Subtle Art of Not Giving a Fuck</td>\n",
       "      <td>206</td>\n",
       "      <td>3.87</td>\n",
       "      <td>Nonfiction, Self Help</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>HarperCollins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Start with Why</td>\n",
       "      <td>256</td>\n",
       "      <td>4.10</td>\n",
       "      <td>Business, Leadership</td>\n",
       "      <td>2009-10-29</td>\n",
       "      <td>Portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Housemaid</td>\n",
       "      <td>329</td>\n",
       "      <td>4.31</td>\n",
       "      <td>Thriller, Mystery</td>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>Bookouture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Housemaid´s Secret</td>\n",
       "      <td>Audible</td>\n",
       "      <td>4.21</td>\n",
       "      <td>Thriller, Mystery</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>Editora Arqueiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atomic Habits</td>\n",
       "      <td>319</td>\n",
       "      <td>4.34</td>\n",
       "      <td>Nonfiction, Self Help</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>Avery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title Page_count Rating  \\\n",
       "0  The Subtle Art of Not Giving a Fuck        206   3.87   \n",
       "1                       Start with Why        256   4.10   \n",
       "2                        The Housemaid        329   4.31   \n",
       "3               The Housemaid´s Secret    Audible   4.21   \n",
       "4                        Atomic Habits        319   4.34   \n",
       "\n",
       "                   Genre First_published         Publisher  \n",
       "0  Nonfiction, Self Help      2016-01-01     HarperCollins  \n",
       "1   Business, Leadership      2009-10-29         Portfolio  \n",
       "2      Thriller, Mystery      2022-04-26        Bookouture  \n",
       "3      Thriller, Mystery      2023-02-15  Editora Arqueiro  \n",
       "4  Nonfiction, Self Help      2018-10-18             Avery  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the new columns to df_books\n",
    "df_books[\"Page_count\"] = new_pages\n",
    "df_books[\"Rating\"] = new_ratings\n",
    "df_books[\"Genre\"] = new_genres\n",
    "df_books[\"First_published\"] = new_dates\n",
    "df_books[\"Publisher\"] = new_publishers\n",
    "\n",
    "# Check a sample\n",
    "df_books[[\"Title\", \"Page_count\", \"Rating\", \"Genre\", \"First_published\", \"Publisher\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce6ff8e-6760-4446-ab09-706e31b37931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as 'book_covers_dataset_goodreads.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the full dataset with all columns\n",
    "df_books.to_csv(\"book_covers_dataset_with_goodreads.csv\", index=False)\n",
    "print(\"File saved as 'book_covers_dataset_with_goodreads.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
